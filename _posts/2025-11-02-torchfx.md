---
layout: post
title: "Torch FX IR"
categories: engineering
use_math: true
author:
- Yue (Julien) Niu
---

Torch FX is a toolkit to transform `torch.nn.Module` instances to a high-level intermediate representation (IR).
It can generate a list of node of operators and the execution flow. 

Compared to LLVM IR, FX is a more high-level IR that generates graph representation consisting standard torch.nn modules.

**A simple example:**

```python
import torch
from torch.fx import symbolic_trace


class MyModule(torch.nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.linear = torch.nn.Linear(4, 5)
        self.activation = torch.nn.ReLU()

    def forward(self, x):
        y = self.linear(x).clamp(min=0.0, max=1.0)
        return self.activation(y)


# test run
module = MyModule()
symbolic_traced: torch.fx.GraphModule = symbolic_trace(module)

print(symbolic_traced.graph)
print(symbolic_traced.code)
```

*symbolic graph*

```text
graph():
    %x : [#users=1] = placeholder[target=x]
    %linear : [#users=1] = call_module[target=linear](args = (%x,), kwargs = {})
    %clamp : [#users=1] = call_method[target=clamp](args = (%linear,), kwargs = {min: 0.0, max: 1.0})
    %activation : [#users=1] = call_module[target=activation](args = (%clamp,), kwargs = {})
    return activation
```

---
